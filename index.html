
<!DOCTYPE html>

<html>

<head>
   <style>
      td, th {
        border: 0px solid black;          
        }
      img{
   padding: 5px;
}
      </style>

  <title>TT_SFUDA</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="shortcut icon" href="./static/images/jhu_web.png" />

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
  <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

<script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>

<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>  -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Target and Task specific Source-Free Domain
            Adaptive Image Segmentation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://vibashan.github.io/">Vibashan VS*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://jeya-maria-jose.github.io/research">Jeya Maria Jose*</a><sup>1</sup>,</span>
            <span>
              <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Johns Hopkins University,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/Vibashan/tt-sfuda"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>code</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Solving the domain shift problem during inference is essential in medical imaging as most deep-learning based solutions suffer from it. 
            In practice, domain shifts are tackled by performing Unsupervised Domain Adaptation (UDA), where a model is adapted to an unlabeled target 
            domain by leveraging the labelled source domain. In medical scenarios, the data comes with huge privacy concerns making it difficult to apply 
            standard UDA techniques. Hence, a closer clinical setting is Source-Free UDA (SFUDA), where we have access to source trained model but not the
            source data during adaptation. Methods trying to solve SFUDA typically address the domain shift using pseudo-label based self-training techniques. 
            However due to domain shift, these pseudo-labels are usually of high entropy and denoising them still does not make them perfect labels to 
            supervise the model. Therefore, adapting the source model with noisy pseudo labels reduces its segmentation capability while addressing the
            domain shift. To this end, we propose a two-stage approach for source-free domain adaptive image segmentation: 1) Target-specific adaptation 
            followed by 2) Task-specific adaptation. In the first stage, we focus on generating target-specific pseudo labels while suppressing 
            high entropy regions by proposing an Ensemble Entropy Minimization loss. We also introduce a  selective voting strategy to enhance pseudo-label
            generation. In the second stage, we focus on adapting the network for task-specific representation by using a teacher-student self-training approach
            based on augmentation-guided consistency. We evaluate our proposed method on both 2D fundus datasets and 3D MRI volumes across 7 different domain 
            shifts where we achieve better performance than recent UDA and SF-UDA methods for medical image segmentation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
              <center>Overview of the proposed framework.</center>
                <img src="./static/images/src-UNet.svg" alt="" border=0 height=500 width=1500></img></
              <p>
                In target-specific adaptation, we propose an ensemble entropy minimization loss
                to reduce the high entropy regions of pseudo-labels. We also introduce a selective 
                voting strategy to enhance pseudo-labels for better supervision. Here, we
                use multiple augmentations to get regions that are consistently of high entropy
                and enhance the pseudo labels based on that information. Thus in Stage I, we
                adapt to the target domain by ensemble entropy minimization and supervise
                with enhanced pseudo-label without losing task-specific information.
              </p> 

              <p>
                In task-specific adaptation, we use a strong-weak augmentation based teacher-student self-training
                framework. Here, ensuring that the predictions are consistent across strong and weak augmentations 
                helps the model learn task-specific information. We also introduce a augmentation-guided feature 
                consistency loss that helps regularize the network for segmentation. Thus in Stage II, we perform 
                student-teacher pseudo-label based self-training to enhance task-specific information of the entropy
                  minimized model from Stage I.
              </p> 
          </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code> </code></pre>
  </div>
</section>

<section class="section" >
  <div class="container is-max-desktop content">
    <h5 class="title">Website Template taken from <span class="author-block">
              <a href="https://nerfies.github.io/" target="_blank">Nerfies</a></h5>

  </div>
</section>

<script>
    const viewers = document.querySelectorAll(".image-compare");
    viewers.forEach((element) => {
        let view = new ImageCompare(element, {
            hoverStart: true,
            addCircle: true
        }).mount();
    });

    $(document).ready(function () {
        var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
            lineNumbers: false,
            lineWrapping: true,
            readOnly: true
        });
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    });
</script>
</body>
</html>
